# 《数据结构与算法分析》(第三版) 笔记

//复杂度上限O, 下限Ω(omega), 但上下限相等 或平均 我们用Θ(theta)

## 一、线性表 List

1. 抽象类声明（抽象数据类型ADT）定义了List, ~List, insert, append, remove, moveToStart, moveToEnd, moveToPos, prev, next, length, currPos, getValue
2. 2种实现方式：array based list(顺序表 数组x)和linked list(链表)
   1. 数组
      1. 优点：每一个元素没有浪费空间（相比链表需要指针）；取第n个元素快
      2. 缺点：不满的时候浪费空间；大小定义后不能改（当然可以用动态数组，但实际加长时时要复制元素的）
   2. 链表
      1. 优点：插入/删除快；大小不限制
   3. 双链表：可以访问前驱节点

二、栈 Stack

	1. 只可访问栈顶元素(top)，操作有入栈(push)和出栈(pop)
 	2. 也包括2种实现方式：arraybased(顺序栈)和list(链式栈)

三、队列 queue

 	1. 操作：enqueue(进队)和dequeue(出队)；front指向前面(刚进队), rear指向最先进的
 	2. 怎么判断队列空或者满（front, rear相同表示1个元素，如果rear小于front表示空，那么和满是一样的）需要n+1个空
 	3. 循环队列(取模来实现)

四、字典 dictionary

1. key；操作：insert, find, remove, removeAny
2. 实现举了2个例子：无序顺序表 和 有序顺序表 insert(1, n), find(n, logn(二分法)), remove(n, n(要移动))
3. comparable(可比性)：运算符重载

五、二叉树

1. 满二叉树、完全二叉树
    1. 满二叉树定理一：非空满二分叉树的叶子结点 = 分支节点+1
    2. 定理二：非空二叉树空子树 = 节点数+1（本质与定理一一样）

2. 深度、高度、路径长度
3. 前序、中序、后序遍历
4. 2种实现：链表 和 数组w
   1. 数组要记录：位置、父节点、左子节点、右子节点、左邻居、右邻居
5. 二叉检索树 BST（必定要平衡，否则达不到检测快速的目的）
   1. 需要保持平衡，删除的节点可由右子树的最小值代替
   2. 建堆时如何保持平衡？
6. 堆 heap（以最大堆为例）
   1. 建堆(bulidHeap)与下拉操作(siftdwon)：siftdown是一个辅助操作，不是单独功能。是在建堆的时候(先随机扔进去变成完全二叉树)，先将左右子树弄成堆的前提下，左右节点选大的和当前顶点交换，(后续遍历)这时交换下来的原顶点可能比现在的子树的小，因此需要把原顶点一直siftdown(和较大子节点交换)到合适的位置。//建堆代价就是siftdown之和 最差Θ(n) 比建立BST的平均Θ(nlogn) 最差Θ(n^2)快很多 至于Θ(n)怎么算的 是由一个∑相加最终得出的
7. huffman编码树：建树不断拿小的(和)加起来

六、树

1. 表示方法：子节点表、左子右兄弟表、动态节点(2种)

七、内排序

1. 3种n^2排序（除了插入排序最佳是Θ(n)，其他各种情况都是Θ(n^2)）
   1. 插入排序：前i-1个排好了，第i个应该插入到哪里 //最佳Θ(n)(2个循环，当内循环只1次插在最后/最前 ), 平均 和 最差 n^2
   2. 冒泡排序：前i-1个排好，每次从底部(最后开始，不断往前交换) // n^2
   3. 选择排序：每次找最小的和当前第i个交换 // n^2

2. Shell排序：第一轮n/2个长度为2，第二轮n/4个长度为4…… 本质是在最后一轮插入排序时，序列已经比较有序，利用插入排序最佳时间n，Shell排序比n^2要好得多，可以理解为复杂度为Θ(n^1.5)
3. 归并排序 Merge Sort（三种情况均为Θ(n logn) 一共logn轮 每轮遍历n个）缺点：需要两倍空间
4. 快速排序 Quick Sort（Θ(n logn) 最差Θ(n^2)）：找轴值(pivot)findPivot交换至末尾 进行Partition(do循环 里面2个while循环 do直到l和r相遇 while是l遇到比pivot大的 r遇到比pivot小的(假设从小到大))
   1. 改进一：findPivot 三者取中法(first、end、中间的) 
   2. 改进儿：较小的数组(长度小于等于9)用插入排序
   3. 堆排序（Θ(n建堆+nlog n取出最大值后调整下筛每次logn)=Θ(n logn)）适合外排序 比快排慢一个常数因子

八、检索

hashing（哈希/散列方法）：两个关键问题——hashing function和collision resolution(冲突解决策略)

1. hashing function

   1. 取模(比如K%16 缺点：则只取决于低4位数)
   2. 平方取中法（较好 多用于数值）
   3. 把字符转成数字 sum%M（用于字符串）

2. 开散列和闭散列

   1. 闭散列

      1. 桶式散列：散列表+溢出表

      2. 改进1：线性探查——探查函数为p(K,i)=i，效果不佳，每个slot(槽)分配到记录的概率不等

       3. 改进2：p(K,i)=ci的线性探查，其中c和M互素（使其能走遍所有slot）但由于差值是一样的 所以还是可能会重叠 比如c=2，h(k1)=3, 探查序列为3, 5, 7…, h(k2)=5, 探查序列为5, 7… 这种现象叫“聚集”或“基本聚集”

       4. 改进3：伪随机探查(pseudo-random probing) p(K,i)=Perm[i-1] (其中Perm()返回一个1～M-1的随机数)

       5. 改进4：二次探查(quadratic probing) p(K,i)=c1 * i^2 + c2 * i + c3(e.g. p(K,i)=i^2) 伪随机和二次探查可以消除基本聚集 但不能消除”二级聚集“ 指的是筛到同个基槽(home position)的关键码 原因是他们所用的探查函数仅依赖于基槽参数 而不依赖K本身 (实际上消除基本聚集的思想只是让不同轮次的探查序列差值不同即可)

       6. 改进5：双散列方法 实际是线性探查变体 p(K,i)=i * h2(K) (其中h2是第二个散列函数 代替了原来的常数c 所以双散列是可以和伪随机探查或二次探查结合起来用的)（消除二级聚集的思想是使得即使探查轮次i相同(比如基槽一样 最终值=h1(K)+p(K,i) 所以此时h1(K)一样 需要使得当i一样时, p(K,i)产生不同值）

        

        分析

      0.	设计要使散列表一半（效果和利用率的平衡）
      0.	访问时可以有两种方法使得检索效率提高
         0.	每次探查把访问的记录与探查序列前一条交换(使访问率高的提前)
         0.	周期性地重新散列整个表
      0.	删除：要保证删除点后的仍能正常访问
         0.	墓碑(tombstone)
         0.	插入时遇到tombstone 记录位置 但仍要探查完 以保证不会同时出现两个相同关键码（tombstone会时超出基槽的长度增加 影响探查效率 解决方法有两种）
            0.	删除时进行一次局部重组 如探查序列后的记录交换到当前删除记录位置
            0.	定期重新散列整个表

九、索引

1. 2-3树的插入：先分裂，然后中间提高等级 插入、检索、删除均为Θ(logn)
2. B树（大型文件访问方法）4阶B树 最多4个子节点 3个关键码
3. B+树（适合范围查询 B+树的叶子包含所有记录(相比于B树 部分记录在内部节点 B+树的内部节点只作索引功能)）
   1. 一棵4阶B+树 内部节点必须2～4个子节点 索引值用每一块的最小值
   2. 删除时 如果记录数减小到小于最低限度（“下溢”）
      1. 找兄弟节点借一个记录 父节点可能需要修改占位关键
      2. 没有兄弟节点可以借给它 它需要把自己的记录让给兄弟节点合并 再看是否需要借节点

十、图

1. 深度优先
2. 宽度优先
3. 单源最短路径问题（指定起点, 终点）——Dijkstra算法
4. 最小支撑树(MST, Minimun-cost spanning tree)(连接起来的总代价最小 不指定起点, 终点)
   1. Prim算法(有点像关注‘边’的Dijkstra 不断加入现有“集合”)
   2. Kruskal算法（每次只是找最小的边 不要求所找的边和现有集合是相连的）